{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbc883b6-799f-4cb1-aafb-1893d6a251bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "from scipy import interpolate\n",
    "from scipy import stats\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44487205-89f4-4f9a-aff9-d3e294aa36dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_000</th>\n",
       "      <th>A_001</th>\n",
       "      <th>A_002</th>\n",
       "      <th>A_010</th>\n",
       "      <th>A_011</th>\n",
       "      <th>A_012</th>\n",
       "      <th>A_020</th>\n",
       "      <th>A_021</th>\n",
       "      <th>A_022</th>\n",
       "      <th>A_100</th>\n",
       "      <th>...</th>\n",
       "      <th>generation_model</th>\n",
       "      <th>plasticity_coeff_init</th>\n",
       "      <th>plasticity_model</th>\n",
       "      <th>moving_avg_window</th>\n",
       "      <th>data_dir</th>\n",
       "      <th>log_dir</th>\n",
       "      <th>trainable_coeffs</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>reward_term</th>\n",
       "      <th>layer_sizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000595</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.000677</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008891</td>\n",
       "      <td>-0.012538</td>\n",
       "      <td>-0.005689</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>-0.005066</td>\n",
       "      <td>-0.012358</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013072</td>\n",
       "      <td>-0.020446</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-0.001320</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.005101</td>\n",
       "      <td>-0.021184</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.015342</td>\n",
       "      <td>-0.022874</td>\n",
       "      <td>-0.000365</td>\n",
       "      <td>-0.004705</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.003133</td>\n",
       "      <td>-0.024057</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.026618</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016122</td>\n",
       "      <td>-0.023495</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>-0.010657</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>0.029459</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.013265</td>\n",
       "      <td>-0.015341</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>-0.004263</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.030822</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.013269</td>\n",
       "      <td>-0.014975</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>-0.001849</td>\n",
       "      <td>-0.001432</td>\n",
       "      <td>0.030885</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.013736</td>\n",
       "      <td>-0.013804</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.031033</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-0.013431</td>\n",
       "      <td>-0.013650</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>-0.001703</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000655</td>\n",
       "      <td>0.028440</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.012713</td>\n",
       "      <td>-0.012469</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>-0.001542</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.027768</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1029 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A_000     A_001     A_002     A_010     A_011     A_012     A_020  \\\n",
       "0    0.000595 -0.000818 -0.000677  0.001305  0.000373 -0.000600  0.000831   \n",
       "1   -0.008891 -0.012538 -0.005689  0.000057 -0.000459 -0.000305 -0.005066   \n",
       "2   -0.013072 -0.020446 -0.000206 -0.001320 -0.000063 -0.000135 -0.005101   \n",
       "3   -0.015342 -0.022874 -0.000365 -0.004705  0.000317  0.000091 -0.003133   \n",
       "4   -0.016122 -0.023495  0.001336 -0.010657 -0.000201 -0.000059  0.000058   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "100 -0.013265 -0.015341  0.001390 -0.004263 -0.000368 -0.000280  0.000775   \n",
       "101 -0.013269 -0.014975 -0.001090 -0.004374 -0.000286  0.000496  0.000557   \n",
       "102 -0.013736 -0.013804 -0.000051 -0.000015 -0.000170 -0.000375 -0.000092   \n",
       "103 -0.013431 -0.013650  0.001319 -0.001703  0.000329  0.000339 -0.000115   \n",
       "104 -0.012713 -0.012469  0.003036 -0.001542 -0.000999 -0.000521  0.000544   \n",
       "\n",
       "        A_021     A_022     A_100  ...  generation_model  \\\n",
       "0    0.001128 -0.000689  0.002647  ...          volterra   \n",
       "1   -0.012358 -0.000032  0.016444  ...          volterra   \n",
       "2   -0.021184 -0.000596  0.022261  ...          volterra   \n",
       "3   -0.024057  0.000223  0.026618  ...          volterra   \n",
       "4   -0.024210 -0.000139  0.029459  ...          volterra   \n",
       "..        ...       ...       ...  ...               ...   \n",
       "100 -0.001693  0.000196  0.030822  ...          volterra   \n",
       "101 -0.001849 -0.001432  0.030885  ...          volterra   \n",
       "102 -0.000434 -0.000125  0.031033  ...          volterra   \n",
       "103  0.000115 -0.000655  0.028440  ...          volterra   \n",
       "104  0.000159  0.000899  0.027768  ...          volterra   \n",
       "\n",
       "     plasticity_coeff_init  plasticity_model  moving_avg_window  data_dir  \\\n",
       "0                   random          volterra                 10  ../data/   \n",
       "1                   random          volterra                 10  ../data/   \n",
       "2                   random          volterra                 10  ../data/   \n",
       "3                   random          volterra                 10  ../data/   \n",
       "4                   random          volterra                 10  ../data/   \n",
       "..                     ...               ...                ...       ...   \n",
       "100                 random          volterra                 10  ../data/   \n",
       "101                 random          volterra                 10  ../data/   \n",
       "102                 random          volterra                 10  ../data/   \n",
       "103                 random          volterra                 10  ../data/   \n",
       "104                 random          volterra                 10  ../data/   \n",
       "\n",
       "     log_dir  trainable_coeffs  exp_name      reward_term  layer_sizes  \n",
       "0      logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "1      logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "2      logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "3      logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "4      logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "..       ...               ...       ...              ...          ...  \n",
       "100    logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "101    logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "102    logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "103    logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "104    logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "\n",
       "[1029 rows x 59 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the csv files in the current directory\n",
    "csv_files = glob.glob(\"../../experiments/logs/simdata/fig4/volterra/exp_*.csv\")\n",
    "\n",
    "# Create a list of dataframes\n",
    "dfs = []\n",
    "\n",
    "# Iterate over the csv files\n",
    "for csv_file in csv_files:\n",
    "\n",
    "    # Read the csv file into a dataframe\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Append the dataframe to the list of dataframes\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes into a single dataframe\n",
    "df = pd.concat(dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baa4ace0-805b-4a2c-8bd1-a043565c64fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epoch', 'loss', 'train_time', 'percent_deviance', 'r2_weights', 'r2_activity', 'num_train', 'num_eval', 'num_epochs', 'trials_per_block', 'log_interval', 'num_blocks', 'log_expdata', 'use_experimental_data', 'flyid', 'fit_data', 'neural_recording_sparsity', 'measurement_noise_scale', 'input_firing_mean', 'input_variance', 'l1_regularization', 'generation_coeff_init', 'generation_model', 'plasticity_coeff_init', 'plasticity_model', 'moving_avg_window', 'data_dir', 'log_dir', 'trainable_coeffs', 'exp_name', 'reward_term', 'layer_sizes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1, 10,  2,  3,  4,  5,  6,  7,  8,  9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs, other_columns = [], []\n",
    "\n",
    "for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                coeffs.append(f\"A_{i}{j}{k}\")\n",
    "\n",
    "for column in df.columns:\n",
    "    if column not in set(coeffs):\n",
    "        other_columns.append(column)\n",
    "print(other_columns)\n",
    "num_epochs = int(np.squeeze(df[\"num_epochs\"].unique()))\n",
    "\n",
    "for coeff in coeffs:\n",
    "    df[coeff] = pd.to_numeric(df[coeff])\n",
    "df[\"moving_avg_window\"] = df[\"moving_avg_window\"].astype(int)\n",
    "df[\"flyid\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e8c2dfc-6c30-4ee8-a19d-80745abce414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_000</th>\n",
       "      <th>A_001</th>\n",
       "      <th>A_002</th>\n",
       "      <th>A_010</th>\n",
       "      <th>A_011</th>\n",
       "      <th>A_012</th>\n",
       "      <th>A_020</th>\n",
       "      <th>A_021</th>\n",
       "      <th>A_022</th>\n",
       "      <th>A_100</th>\n",
       "      <th>...</th>\n",
       "      <th>generation_model</th>\n",
       "      <th>plasticity_coeff_init</th>\n",
       "      <th>plasticity_model</th>\n",
       "      <th>moving_avg_window</th>\n",
       "      <th>data_dir</th>\n",
       "      <th>log_dir</th>\n",
       "      <th>trainable_coeffs</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>reward_term</th>\n",
       "      <th>layer_sizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.005134</td>\n",
       "      <td>-0.004499</td>\n",
       "      <td>0.010370</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.023210</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.003856</td>\n",
       "      <td>-0.003252</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>-0.017517</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.008389</td>\n",
       "      <td>-0.010192</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>-0.003466</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.026175</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-0.005667</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.009638</td>\n",
       "      <td>-0.003292</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.023849</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.010861</td>\n",
       "      <td>-0.014304</td>\n",
       "      <td>0.010704</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>-0.024591</td>\n",
       "      <td>-0.000632</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>...</td>\n",
       "      <td>volterra</td>\n",
       "      <td>random</td>\n",
       "      <td>volterra</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/</td>\n",
       "      <td>logs/</td>\n",
       "      <td>27</td>\n",
       "      <td>fig4</td>\n",
       "      <td>expected-reward</td>\n",
       "      <td>[2, 10, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A_000     A_001     A_002     A_010     A_011     A_012     A_020  \\\n",
       "20  -0.005134 -0.004499  0.010370 -0.000448  0.000067 -0.000091  0.000014   \n",
       "41  -0.003856 -0.003252  0.009820 -0.001037 -0.000117  0.000011 -0.000247   \n",
       "62  -0.008389 -0.010192  0.009669 -0.003466 -0.000214 -0.000568 -0.000015   \n",
       "83  -0.005667 -0.006031  0.009638 -0.003292 -0.000256 -0.000747  0.000075   \n",
       "104 -0.010861 -0.014304  0.010704 -0.000242  0.000056 -0.000620  0.000266   \n",
       "\n",
       "        A_021     A_022     A_100  ...  generation_model  \\\n",
       "20  -0.023210 -0.000238  0.005447  ...          volterra   \n",
       "41  -0.017517 -0.000081  0.000214  ...          volterra   \n",
       "62  -0.026175 -0.000146  0.015286  ...          volterra   \n",
       "83  -0.023849 -0.000022  0.009683  ...          volterra   \n",
       "104 -0.024591 -0.000632  0.018759  ...          volterra   \n",
       "\n",
       "     plasticity_coeff_init  plasticity_model  moving_avg_window  data_dir  \\\n",
       "20                  random          volterra                 10  ../data/   \n",
       "41                  random          volterra                 10  ../data/   \n",
       "62                  random          volterra                 10  ../data/   \n",
       "83                  random          volterra                 10  ../data/   \n",
       "104                 random          volterra                 10  ../data/   \n",
       "\n",
       "     log_dir  trainable_coeffs  exp_name      reward_term  layer_sizes  \n",
       "20     logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "41     logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "62     logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "83     logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "104    logs/                27      fig4  expected-reward   [2, 10, 1]  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = df.loc[(df['epoch'] == num_epochs)]\n",
    "for coeff in coeffs:\n",
    "    if df_subset[coeff].sum() == 0:\n",
    "        df_subset = df_subset.drop(coeff, axis=1)\n",
    "\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b44b3e6-7a57-4502-93d7-2d40345fa11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = \"ticks\"\n",
    "sns.set_style(style)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ax.set_title('% Deviance Explained')\n",
    "\n",
    "box_plot = sns.boxplot(data=df_subset, x=\"measurement_noise_scale\", y=\"percent_deviance\", width=0.5)\n",
    "ax.set_xlabel(\"Gaussian noise scale\", fontsize=13, fontweight=\"light\")\n",
    "ax.set_ylabel(\"%\")\n",
    "ax.legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig4-noise.png\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147768b-0274-4c38-b667-60881b2ba575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597694d-ab29-42fb-a4a5-97f724af0855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mb",
   "language": "python",
   "name": "mb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
